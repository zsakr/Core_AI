import cv2
from inference import get_model
from ultralytics import YOLO
import supervision as sv
from collections import deque
import numpy as np
import torch

# === Load Models ===
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"Using device: {device}")

ball_model = get_model(
    model_id="sq-ball-detection-e7bul/1",
    api_key="QJen0rGApuNHlCEwrqfj"  # Replace with your real key
)
player_model = YOLO("yolov8s.pt")
pose_model = YOLO("yolov8x-pose.pt")
player_model.to(device)
pose_model.to(device)

# === Video Setup ===
input_video = "D:/Python/assets/Untitled video - Made with Clipchamp.mp4"
output_video = "heatmap_output.mp4"

cap = cv2.VideoCapture(input_video)
if not cap.isOpened():
    raise IOError(f"Cannot open video file: {input_video}")

frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)
frame_time = 1.0 / fps

out = cv2.VideoWriter(
    output_video,
    cv2.VideoWriter_fourcc(*'mp4v'),
    fps,
    (frame_width, frame_height)
)

# === Scale: pixels → meters ===
PIXELS_PER_METER = 100.0  # e.g. 100 px = 1 m
MAX_DIST_PER_FRAME_M = 1.0  # Ignore any jump > 1 meter per frame

# === Annotators & Visuals ===
box_annotator = sv.BoxAnnotator()
label_annotator = sv.LabelAnnotator()
trail = deque(maxlen=5)
palette = sv.ColorPalette.DEFAULT

# === Heatmap Accumulators ===
heatmap_accum_1 = np.zeros((frame_height, frame_width), dtype=np.float32)
heatmap_accum_2 = np.zeros((frame_height, frame_width), dtype=np.float32)

# === For speed and distance calculation ===
prev_positions = {}      # Holds previous ankle positions per player ID
# Holds total ankle‐based distances (in meters) per player ID
total_distances = {}
prev_ball_pos = None     # Separate storage for ball's last‐seen position

# For "one" mode: store shirt histogram of the target
target_shirt_hist = None

# --- Ask user whether to track one or both players ---
track_mode = input("Track one or both players? (one/both): ").strip().lower()
if track_mode == "one":
    target_player_id = int(
        input("Which player do you want to track? (tracker_id): "))
    print("Processing video with heatmap and metrics for player ID:", target_player_id)
elif track_mode == "both":
    print("Processing video with heatmaps and metrics for both top players.")
else:
    raise ValueError("Invalid input. Please enter 'one' or 'both'.")

frame_index = 0


def compute_iou(boxA, boxB):
    """
    Compute IoU between boxA and boxB.
    boxA, boxB: [x1, y1, x2, y2]
    """
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])
    interW = max(0, xB - xA)
    interH = max(0, yB - yA)
    interArea = interW * interH
    if interArea == 0:
        return 0.0
    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])
    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])
    return interArea / float(boxAArea + boxBArea - interArea)


def get_shirt_hist(frame, box):
    """
    Compute a normalized Hue histogram for the upper-third ("shirt") region of a bounding box.
    box: [x1, y1, x2, y2], frame in BGR.
    """
    x1, y1, x2, y2 = box.astype(int)
    h = y2 - y1
    # Define shirt region as top third of the bounding box
    shirt_y2 = y1 + h // 3
    shirt_region = frame[y1:shirt_y2, x1:x2]
    if shirt_region.size == 0:
        return None
    hsv = cv2.cvtColor(shirt_region, cv2.COLOR_BGR2HSV)
    # Compute 1D Hue histogram with 50 bins, range [0,180]
    hist = cv2.calcHist([hsv], [0], None, [50], [0, 180])
    cv2.normalize(hist, hist, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)
    return hist


while True:
    ret, frame = cap.read()
    if not ret:
        break

    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # --- Ball Detection ---
    ball_results = ball_model.infer(rgb_frame)[0]
    ball_detections = sv.Detections.from_inference(ball_results)

    # --- Player Detection with tracking ---
    results = player_model.track(
        frame, persist=True, classes=[0], verbose=False, device=device
    )
    player_detections = sv.Detections.from_ultralytics(results[0])
    player_boxes = player_detections.xyxy.copy()  # shape: (N_players, 4)
    player_ids = player_detections.tracker_id if player_detections.tracker_id is not None else []

    # --- Pose Estimation (YoloV8x‐Pose) ---
    pose_results = pose_model(frame)[0]
    if hasattr(pose_results, "boxes") and pose_results.boxes is not None:
        pose_boxes = pose_results.boxes.xyxy.cpu().numpy()    # (N_pose, 4)
        pose_kps = pose_results.keypoints.data.cpu().numpy()  # (N_pose, 17, 3)
    else:
        pose_boxes = np.zeros((0, 4))
        pose_kps = np.zeros((0, 17, 3))

    # If more than two players detected, keep top2 by confidence (for "both" mode)
    if len(player_boxes) > 2:
        top2 = np.argsort(player_detections.confidence)[-2:][::-1]
        player_boxes = player_boxes[top2]
        player_detections.xyxy = player_boxes
        player_detections.confidence = player_detections.confidence[top2]
        player_detections.class_id = player_detections.class_id[top2]
        if player_ids is not None:
            player_ids = [player_ids[i] for i in top2]

    # --- Shadow Rendering under players ---
    annotated_frame = frame.copy()
    overlay = frame.copy()
    for box in player_boxes:
        x1, y1, x2, y2 = box.astype(int)
        center_x = (x1 + x2) // 2
        center_y = y2 + 10
        width = int((x2 - x1) * 0.8)
        height = int((x2 - x1) * 0.25)

        y1_clip = np.clip(y1, 0, frame.shape[0])
        y2_clip = np.clip(y1 + (y2 - y1) // 4, 0, frame.shape[0])
        shirt_region = frame[y1_clip:y2_clip, x1:x2]

        if shirt_region.size == 0:
            shadow_color = (30, 30, 30)
        else:
            avg_color = shirt_region.mean(axis=(0, 1)).astype(int)
            b, g, r = avg_color
            factor = 1.3
            shadow_color = tuple(int(c) for c in np.clip(
                [b * factor, g * factor, r * factor], 0, 255))

        cv2.ellipse(overlay, (center_x, center_y),
                    (width // 2, height), 0, 0, 360, shadow_color, -1)

    cv2.addWeighted(overlay, 0.7, annotated_frame, 0.3, 0, annotated_frame)

    # --- Ball Trail ---
    if len(ball_detections.xyxy) > 0:
        x1, y1, x2, y2 = ball_detections.xyxy[0]
        cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
        trail.append((cx, cy))

    for i in range(1, len(trail)):
        if trail[i - 1] and trail[i]:
            thickness = int(8 * (1 - i / len(trail))) + 1
            color = (0, 255 - i * 7, 255)
            cv2.line(annotated_frame, trail[i - 1], trail[i], color, thickness)

    # === Process Players & Update Heatmaps / Distances ===
    player_speeds = {}  # speeds in m/s

    # 1) Compute shirt histogram for each detected player box this frame
    shirt_hists = []
    for box in player_boxes:
        hist = get_shirt_hist(frame, box)
        shirt_hists.append(hist)

    # 2) If in "one" mode, find which box corresponds to target by histogram match
    target_idx = None
    if track_mode == "one":
        if frame_index == 0:
            for i, tid in enumerate(player_ids):
                if tid == target_player_id:
                    if shirt_hists[i] is not None:
                        target_shirt_hist = shirt_hists[i].copy()
                    target_idx = i
                    break
        else:
            best_score = -1.0
            best_i = -1
            for i, hist in enumerate(shirt_hists):
                if hist is None or target_shirt_hist is None:
                    continue
                score = cv2.compareHist(
                    hist, target_shirt_hist, cv2.HISTCMP_CORREL)
                if score > best_score:
                    best_score = score
                    best_i = i
            if best_score > 0.4:
                target_idx = best_i
            else:
                target_idx = None

    # 3) Match each player box to pose index via IoU > 0.3
    matched_pose_idx = {}
    for i, box in enumerate(player_boxes):
        best_iou = 0.0
        best_j = -1
        for j, pbox in enumerate(pose_boxes):
            iou = compute_iou(box, pbox)
            if iou > best_iou:
                best_iou = iou
                best_j = j
        if best_iou > 0.3:
            matched_pose_idx[i] = best_j

    # 4) Build a fresh dict of “current ankle positions” for tracked players
    current_positions = {}  # { pid: (ankle_x, ankle_y) }

    # 5) Loop through players for drawing, heatmap, and ankle‐distance
    for i, box in enumerate(player_boxes):
        x1, y1, x2, y2 = box.astype(int)
        feet_x = (x1 + x2) // 2
        feet_y = y2

        # Decide if we draw bounding box around this player
        draw_box = False
        if track_mode == "one":
            if i == target_idx:
                draw_box = True
        else:  # "both"
            if i < 2:
                draw_box = True

        if draw_box:
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)

        # --- HEATMAP update ---
        if track_mode == "one":
            if i == target_idx:
                heatmap_accum_1[feet_y, feet_x] += 1.0
        else:
            if i == 0:
                heatmap_accum_1[feet_y, feet_x] += 1.0
            elif i == 1:
                heatmap_accum_2[feet_y, feet_x] += 1.0

        # --- ANKLE‐BASED DISTANCE (only for the tracked player in "one", or top2 in "both") ---
        if ((track_mode == "one" and i == target_idx) or (track_mode == "both" and i < 2)):

            # Extract ankle keypoints if matched to a pose
            ankle_x, ankle_y = None, None
            if i in matched_pose_idx:
                j = matched_pose_idx[i]
                person_kp = pose_kps[j]  # shape (17, 3)
                lx, ly, lc = person_kp[15]  # left ankle
                rx, ry, rc = person_kp[16]  # right ankle

                if lc > 0.3 and rc > 0.3:
                    ankle_x = (lx + rx) / 2
                    ankle_y = (ly + ry) / 2
                elif lc > 0.3:
                    ankle_x, ankle_y = lx, ly
                elif rc > 0.3:
                    ankle_x, ankle_y = rx, ry

            # Fallback: box bottom‐center if ankles aren’t found
            if ankle_x is None or ankle_y is None:
                ankle_x = float(feet_x)
                ankle_y = float(feet_y)

            pid = player_ids[i]
            current_positions[pid] = (ankle_x, ankle_y)

            # ---- Compute distance only if pid was in prev_positions last frame ----
            if pid in prev_positions:
                prev_ankle = prev_positions[pid]
                dist_px = np.linalg.norm(
                    np.array((ankle_x, ankle_y)) - np.array(prev_ankle))
                dist_m = dist_px / PIXELS_PER_METER

                # Filter out implausible jumps > MAX_DIST_PER_FRAME_M
                if dist_m <= MAX_DIST_PER_FRAME_M and dist_m > 0:
                    # Accumulate in meters
                    total_distances[pid] = total_distances.get(
                        pid, 0.0) + dist_m
                    # Speed in m/s
                    player_speeds[pid] = dist_m / frame_time
                else:
                    # Treat as zero movement for this frame
                    player_speeds[pid] = 0.0
            else:
                # First sighting of this pid (or it disappeared last frame)
                total_distances[pid] = total_distances.get(pid, 0.0)
                player_speeds[pid] = 0.0

            # Draw a circle at ankle location
            cv2.circle(annotated_frame, (int(ankle_x),
                       int(ankle_y)), 4, (255, 0, 0), -1)

    # 6) After processing all players, retain any pid from previous frame that disappeared
    new_prev_positions = {}
    for pid, coords in current_positions.items():
        new_prev_positions[pid] = coords
    for pid, coords in prev_positions.items():
        if pid not in new_prev_positions:
            new_prev_positions[pid] = coords
    prev_positions = new_prev_positions

    # --- Ball speed calculation (in m/s) ---
    ball_speed = 0.0
    if len(ball_detections.xyxy) > 0:
        x1, y1, x2, y2 = ball_detections.xyxy[0]
        ball_pos = (int((x1 + x2) / 2), int((y1 + y2) / 2))
        if prev_ball_pos is not None:
            dist_ball_px = np.linalg.norm(
                np.array(ball_pos) - np.array(prev_ball_pos))
            dist_ball_m = dist_ball_px / PIXELS_PER_METER
            if dist_ball_m > 0:
                ball_speed = dist_ball_m / frame_time
            else:
                ball_speed = 0.0
        prev_ball_pos = ball_pos
    else:
        ball_speed = 0.0
        prev_ball_pos = None

    # --- Heatmap Visualization ---
    if track_mode == "one":
        combined_heatmap = heatmap_accum_1
    else:
        combined_heatmap = heatmap_accum_1 + heatmap_accum_2

    heatmap_norm = cv2.normalize(
        combined_heatmap, None, 0, 255, cv2.NORM_MINMAX)
    heatmap_uint8 = heatmap_norm.astype(np.uint8)
    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_HOT)

    overlay_heatmap = cv2.addWeighted(
        annotated_frame, 0.7, heatmap_color, 0.3, 0)

    # --- Display metrics in top-right corner ---
    x_text = frame_width - 10
    y_text = 30
    line_height = 25

    # Conversion factor: m/s → mph
    MS_TO_MPH = 2.23694

    if track_mode == "one":
        speed_mps = player_speeds.get(target_player_id, 0.0)
        speed_mph = speed_mps * MS_TO_MPH
        dist_val = total_distances.get(target_player_id, 0.0)
        ball_mph = ball_speed * MS_TO_MPH
        metrics_text = [
            f"Player ID: {target_player_id}",
            f"Player Speed: {speed_mph:.2f} mph",
            f"Distance Moved: {dist_val:.2f} m",
            f"Ball Speed: {ball_mph:.2f} mph"
        ]
    else:
        ball_mph = ball_speed * MS_TO_MPH
        metrics_text = [f"Ball Speed: {ball_mph:.2f} mph"]
        for i, pid in enumerate(player_ids[:2]):
            speed_mps = player_speeds.get(pid, 0.0)
            speed_mph = speed_mps * MS_TO_MPH
            dist_val = total_distances.get(pid, 0.0)
            metrics_text.append(f"Player {pid} Speed: {speed_mph:.2f} mph")
            metrics_text.append(f"Player {pid} Dist: {dist_val:.2f} m")

    for i, line in enumerate(metrics_text):
        text_size, _ = cv2.getTextSize(line, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
        text_w, _ = text_size
        cv2.putText(
            overlay_heatmap,
            line,
            (x_text - text_w, y_text + i * line_height),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (0, 255, 255),
            2,
            cv2.LINE_AA
        )

    # --- Draw Pose Keypoints (for matched players only) ---
    if hasattr(pose_results, "keypoints") and pose_results.keypoints is not None:
        for i, pid in enumerate(player_ids):
            if (track_mode == "one" and i != target_idx) or (track_mode == "both" and i not in [0, 1]):
                continue
            if i not in matched_pose_idx:
                continue
            j = matched_pose_idx[i]
            person_kp = pose_kps[j]
            for keypoint in person_kp:
                x, y, conf = keypoint
                if conf > 0.5:
                    cv2.circle(overlay_heatmap, (int(x), int(y)),
                               5, (0, 255, 0), -1)

    # --- Write frame ---
    out.write(overlay_heatmap)
    frame_index += 1
    print(f"Processed frame {frame_index}")

# === Save heatmap image(s) after processing ===


def save_heatmap(accum, filename):
    norm = cv2.normalize(accum, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    heatmap_img = cv2.applyColorMap(norm, cv2.COLORMAP_HOT)
    cv2.imwrite(filename, heatmap_img)


if track_mode == "one":
    save_heatmap(heatmap_accum_1, "heatmap_player.png")
    print("Heatmap image saved as heatmap_player.png")
else:
    save_heatmap(heatmap_accum_1, "heatmap_player1.png")
    save_heatmap(heatmap_accum_2, "heatmap_player2.png")
    print("Heatmap images saved as heatmap_player1.png and heatmap_player2.png")

# Save the last frame with heatmap and metrics
cv2.imwrite("last_frame.png", overlay_heatmap)
print("Last frame saved as last_frame.png")

# === Cleanup ===
cap.release()
out.release()
cv2.destroyAllWindows()
print(f"Processing complete. Output saved as {output_video}")
